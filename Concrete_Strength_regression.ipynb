{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jOX8n07YV3z"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.11.2' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "# pandas: high‑performance, easy-to-use data structures (DataFrame) and data analysis tools\n",
        "import pandas as pd\n",
        "# NumPy: support for large, multi-dimensional arrays and matrices, along with a collection of mathematical functions\n",
        "import numpy as np\n",
        "# seaborn: statistical data visualization built on top of matplotlib; provides attractive default styles\n",
        "import seaborn as sns\n",
        "# matplotlib.pyplot: core plotting API for creating figures, axes, and a wide range of plot types\n",
        "from matplotlib import pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs6iEnIjYY4c",
        "outputId": "3ba9bfdb-3e6c-4fe6-c82a-82e17e969e7b"
      },
      "outputs": [],
      "source": [
        "# Import the Colab-specific module that provides access to Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mounts your Google Drive at the specified path in the Colab VM filesystem.\n",
        "# You’ll be prompted to visit an authorization URL, sign in to your Google account,\n",
        "# and paste the resulting auth code here.\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQqDlt_YYV32"
      },
      "source": [
        "# Name -- Data Type -- Measurement -- Description\n",
        "\n",
        "1. Cement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "2. Blast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "3. Fly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "4. Water (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "5. Superplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "6. Coarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "7. Fine Aggregate (component 7) -- quantitative -- kg in a m3 mixture -- Input Variable\n",
        "\n",
        "8. Age -- quantitative -- Day (1~365) -- Input Variable\n",
        "\n",
        "9. Concrete compressive strength -- quantitative -- MPa -- Output Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YmpXBZqFYV35",
        "outputId": "7b2c103e-d6b6-4f29-8e5c-96cfd8ea2299"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file from the mounted Drive into a pandas DataFrame.\n",
        "# The path \"/content/Concrete_Data_Yeh.csv\" refers to the file in Colab's filesystem\n",
        "# (e.g. \"/content/drive/My Drive/…\" if you mounted under Drive).\n",
        "data = pd.read_csv(\"/content/Concrete_Data_Yeh.csv\")\n",
        "\n",
        "# Display the first five rows of the DataFrame to verify it loaded correctly\n",
        "# and to get a quick look at column names and sample values.\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zH4PW88Hg9vS",
        "outputId": "cbac48ab-7f82-4af4-e0c3-edf0682659ab"
      },
      "outputs": [],
      "source": [
        "#to see a quick look of first 10 rows\n",
        "data.head(100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0eG7TaHjYV36",
        "outputId": "66c84974-39f3-4319-9732-5115b61e70b2"
      },
      "outputs": [],
      "source": [
        "# Set up a large plotting canvas (25×25 inches) so that all cells and labels\n",
        "# in the heatmap are easily readable.\n",
        "plt.figure(figsize=(25, 25))\n",
        "\n",
        "# Compute the pairwise correlation matrix of your DataFrame and plot it:\n",
        "# - data.corr() calculates Pearson correlation coefficients between every pair of columns.\n",
        "# - annot=True writes each correlation value into its corresponding cell.\n",
        "# - cmap='RdYlGn' applies a diverging red→yellow→green palette,\n",
        "#   where strong negative correlations are red, neutral are yellow, and strong positives are green.\n",
        "sns.heatmap(data.corr(), annot=True, cmap='RdYlGn')\n",
        "\n",
        "# Display the completed heatmap in the output.\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "_uoDcoPlknF-",
        "outputId": "fd33887b-2388-4489-b4a8-941d06ac7909"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Identify the target column (assumed to be the last one in the DataFrame)\n",
        "target_col = data.columns[-1]\n",
        "\n",
        "# Compute Pearson correlations of every feature with the target variable,\n",
        "# then drop the target’s self‑correlation and sort ascending for plotting\n",
        "corr_with_target = (\n",
        "    data.corr()[target_col]\n",
        "    .drop(target_col)\n",
        "    .sort_values()\n",
        ")\n",
        "\n",
        "# Create a horizontal bar chart to visualize which features\n",
        "# are most positively or negatively correlated with compressive strength\n",
        "plt.figure(figsize=(10, 6))                 # size in inches\n",
        "corr_with_target.plot(kind='barh')           # horizontal bar plot\n",
        "plt.title(f'Feature Correlation with {target_col}')\n",
        "plt.xlabel('Pearson Correlation Coefficient')\n",
        "plt.ylabel('Feature')\n",
        "plt.tight_layout()                           # adjust margins\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "nFLQC1EPlu1N",
        "outputId": "d7860045-e2ed-4412-886a-5b5c9636c122"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute correlations with the target variable (assumed last column)\n",
        "target_col = data.columns[-1]\n",
        "corr_with_target = data.corr()[target_col].drop(target_col)\n",
        "\n",
        "# Count how many features are positively vs. negatively correlated\n",
        "pos_count = (corr_with_target > 0).sum()\n",
        "neg_count = (corr_with_target < 0).sum()\n",
        "\n",
        "# Prepare labels and sizes for the pie chart\n",
        "labels = ['Positive Correlation', 'Negative Correlation']\n",
        "sizes = [pos_count, neg_count]\n",
        "\n",
        "# Create the pie chart\n",
        "plt.figure(figsize=(6, 6))           # square figure for a circular pie\n",
        "plt.pie(\n",
        "    sizes,\n",
        "    labels=labels,\n",
        "    autopct='%1.1f%%',               # show percentages with one decimal\n",
        "    startangle=90                    # rotate start so first slice is at 12 o’clock\n",
        ")\n",
        "plt.title('Proportion of Features by Correlation Sign\\nwith ' + target_col)\n",
        "plt.axis('equal')                    # ensure pie is drawn as a circle\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0C5c1iUYV38"
      },
      "source": [
        "# OBSERVATIONS:\n",
        "    \n",
        "We observe a good positive correlation between csMPa and :\n",
        "    1. Cement\n",
        "    2. Age\n",
        "    3. Superplasticizer\n",
        "    \n",
        "We also observe a good negetive correlation between csMPa and:\n",
        "    1. Water\n",
        "\n",
        "Superplasticizer and water have a very strong negetive correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-V8sB00TYV39",
        "outputId": "ca6416ee-2b8e-415c-f862-90dd9ed78298"
      },
      "outputs": [],
      "source": [
        "# Set up a large, square plotting area (15×15 inches) so that points and axes labels\n",
        "# are clearly visible and not cramped.\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "# Create a scatter plot showing the relationship between:\n",
        "# - 'cement' (x-axis): amount of cement in the mix\n",
        "# - 'csMPa' (y-axis): resulting compressive strength in MPa\n",
        "# The `data` parameter tells matplotlib to pull these columns from the DataFrame.\n",
        "plt.scatter(\n",
        "    x='cement',\n",
        "    y='csMPa',\n",
        "    data=data\n",
        ")\n",
        "\n",
        "# Render the plot in the output cell.\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VeKA_d5GYV3-",
        "outputId": "42de60f4-0f0f-40f6-cf59-941d324d8b9f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (20,20))\n",
        "plt.scatter(x = 'age',\n",
        "           y = 'csMPa',\n",
        "           data = data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VLxxBibcYV3_",
        "outputId": "74b96755-6181-400e-810e-a0031b9178e3"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,15))\n",
        "plt.scatter(x = 'superplasticizer',\n",
        "           y = 'csMPa',\n",
        "           data = data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "92M5ToKLYV3_",
        "outputId": "bcd3f9b8-5b7e-4765-ec5e-98ec9cbe78a7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,15))\n",
        "plt.scatter(x = 'water',\n",
        "           y = 'superplasticizer',\n",
        "           data = data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evE78-HCYV4A"
      },
      "source": [
        "The observations made have been shown above in the graphs above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "eZn5vgcGYV4B",
        "outputId": "042c6217-e85e-412d-c20d-0ae9092e1627"
      },
      "outputs": [],
      "source": [
        "# Get a list of all column names in the DataFrame\n",
        "fields = list(data.keys())\n",
        "\n",
        "# Loop over each column to compute a centered-and-scaled version\n",
        "for field in fields:\n",
        "    # Extract the column’s values (a pandas Series)\n",
        "    values = data[field]\n",
        "\n",
        "    # Compute the maximum value (for scaling denominator)\n",
        "    maximum = max(values)\n",
        "\n",
        "    # Compute the mean (for centering)\n",
        "    avg = sum(values) / len(values)\n",
        "\n",
        "    # Initialize a list to hold the scaled values for this column\n",
        "    scaled_values = []\n",
        "\n",
        "    # For each original value, apply (value – mean) ÷ max\n",
        "    for value in values:\n",
        "        scaled_values.append((value - avg) / maximum)\n",
        "\n",
        "    # Convert the list to a NumPy array for performance\n",
        "    scaled_array = np.array(scaled_values)\n",
        "\n",
        "    # Add the scaled data back into the DataFrame as a new column\n",
        "    data[\"Scaled_\" + field] = scaled_array\n",
        "\n",
        "# Preview the DataFrame to verify that the new columns have been added\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "orrxbXR5YV4B",
        "outputId": "09bde7fc-1f42-4df6-ce88-d46c315967ff"
      },
      "outputs": [],
      "source": [
        "for field in fields:\n",
        "    data.drop([field], axis = 1, inplace = True)\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYi24vOCYV4C"
      },
      "outputs": [],
      "source": [
        "y = data[\"Scaled_csMPa\"]\n",
        "data.drop([\"Scaled_csMPa\"], axis = 1, inplace = True)\n",
        "X = data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "VjqtyhkFYV4D",
        "outputId": "9f59168d-6325-4b31-831a-f3e001557b57"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "DCRJ2BFgYV4D",
        "outputId": "dd70952f-7884-4c0d-920f-b4bb47050b7d"
      },
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhZoi_LTYV4E"
      },
      "source": [
        "# Train Test Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAJhKxCuYV4E"
      },
      "outputs": [],
      "source": [
        "# Import the function to split arrays or matrices into random train and test subsets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split features (X) and target (y) into training and testing sets:\n",
        "# - test_size=0.3 reserves 30% of the data for testing, 70% for training\n",
        "# - random_state=20 ensures the split is reproducible across runs\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.3,\n",
        "    random_state=20\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h85K46qDYV4F",
        "outputId": "477c0618-6ea7-4f44-b6f6-8350c939ae69"
      },
      "outputs": [],
      "source": [
        "# Print the shape of the training features array:\n",
        "# - First value = number of training samples\n",
        "# - Second value = number of features (predictor variables)\n",
        "print(X_train.shape)\n",
        "\n",
        "# Print the shape of the training target array/vector:\n",
        "# - Only one value (number of training samples), since y is 1‑dimensional\n",
        "print(y_train.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "_G74MWka1lcM",
        "outputId": "1a21d004-fddf-4a05-d6dc-6433345035bd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Determine the number of samples in the training and test sets\n",
        "train_count = X_train.shape[0]\n",
        "test_count = X_test.shape[0]\n",
        "\n",
        "# Prepare labels and sizes for the pie chart\n",
        "labels = ['Training Samples', 'Test Samples']\n",
        "sizes = [train_count, test_count]\n",
        "\n",
        "# Create a square figure so the pie will be circular\n",
        "plt.figure(figsize=(6, 6))\n",
        "\n",
        "# Draw the pie chart:\n",
        "# - autopct='%1.1f%%' shows each slice’s percentage\n",
        "# - startangle=90 rotates the first slice to the top (12 o’clock)\n",
        "plt.pie(\n",
        "    sizes,\n",
        "    labels=labels,\n",
        "    autopct='%1.1f%%',\n",
        "    startangle=90\n",
        ")\n",
        "\n",
        "# Add a title to describe what the chart represents\n",
        "plt.title('Proportion of Training vs. Test Samples')\n",
        "\n",
        "# Ensure the pie is drawn as a circle\n",
        "plt.axis('equal')\n",
        "\n",
        "# Display the chart\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdjuhFwiYV4G"
      },
      "source": [
        "# Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "VhVVkqu7YV4G",
        "outputId": "cd7266d9-7fbb-479a-cd12-58a20d94ecf7"
      },
      "outputs": [],
      "source": [
        "# Import the LinearRegression estimator from scikit-learn\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create an instance of the LinearRegression model with default settings\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit (train) the model on your training data:\n",
        "# - X_train: feature matrix for the training set\n",
        "# - y_train: target values corresponding to X_train\n",
        "model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "7CgoPYIj3gYO",
        "outputId": "f140045f-c917-47b1-e998-525d580849d3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Define your estimator/model (here we use linear regression as an example)\n",
        "model = LinearRegression()\n",
        "\n",
        "# 2. Use learning_curve to compute training and cross-validation scores\n",
        "#    - X, y: your full feature matrix and target vector\n",
        "#    - train_sizes: fractions of the training data to use for generating the curve\n",
        "#    - cv: number of folds for cross‑validation\n",
        "#    - scoring: metric to evaluate (here we use R² score)\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    estimator=model,\n",
        "    X=X,\n",
        "    y=y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
        "    cv=5,\n",
        "    scoring='r2',\n",
        "    n_jobs=-1      # use all available CPU cores\n",
        ")\n",
        "\n",
        "# 3. Compute the mean and standard deviation across folds for both sets\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std  = np.std(train_scores, axis=1)\n",
        "test_mean  = np.mean(test_scores, axis=1)\n",
        "test_std   = np.std(test_scores, axis=1)\n",
        "\n",
        "# 4. Plot the learning curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(train_sizes, train_mean, 'o-', label='Training score')\n",
        "plt.fill_between(train_sizes,\n",
        "                 train_mean - train_std,\n",
        "                 train_mean + train_std,\n",
        "                 alpha=0.1)  # shade for one std dev\n",
        "\n",
        "plt.plot(train_sizes, test_mean, 'o-', label='Cross-validation score')\n",
        "plt.fill_between(train_sizes,\n",
        "                 test_mean - test_std,\n",
        "                 test_mean + test_std,\n",
        "                 alpha=0.1)\n",
        "\n",
        "# 5. Customize the plot\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Number of Training Samples')\n",
        "plt.ylabel('R² Score')\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True)\n",
        "\n",
        "# 6. Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QFwv0gMYV4H"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 1) Instantiate\n",
        "model = LinearRegression()\n",
        "\n",
        "# 2) Fit on training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 3) Now you can predict on test data\n",
        "y_predict = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lASHD24fYV4H",
        "outputId": "ce894eec-cb2f-4f94-df80-16a6063b6dec"
      },
      "outputs": [],
      "source": [
        "# Create a large square plotting area (25×25 inches) for maximum readability\n",
        "plt.figure(figsize=(25, 25))\n",
        "\n",
        "# Convert the true and predicted values into plain Python lists\n",
        "# (matplotlib will accept pandas Series too, but this makes it explicit)\n",
        "Y_test = [i for i in y_test]\n",
        "Y_predict = [j for j in y_predict]\n",
        "\n",
        "# Draw a scatter plot of actual vs. predicted values:\n",
        "# - x-axis: true compressive strength (y_test)\n",
        "# - y-axis: model’s predicted strength (y_predict)\n",
        "plt.scatter(Y_test, Y_predict)\n",
        "\n",
        "# Optionally, plot a 45° reference line to see perfect predictions\n",
        "# plt.plot(Y_test, Y_test, 'r--', label='Perfect prediction')\n",
        "\n",
        "# Add labels and a title for clarity\n",
        "plt.xlabel('Actual Compressive Strength (MPa)')\n",
        "plt.ylabel('Predicted Compressive Strength (MPa)')\n",
        "plt.title('Actual vs. Predicted: Linear Regression Results')\n",
        "# plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Np-2_yVs9OsL",
        "outputId": "21c6ac2e-efb8-4a6b-9cff-b4151ab81fee"
      },
      "outputs": [],
      "source": [
        "# Import matplotlib’s plotting interface\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Compute residuals: the difference between the true values and the model’s predictions\n",
        "residuals = y_test - y_predict\n",
        "\n",
        "# Start a new figure with a defined size (8×6 inches)\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Plot a histogram of the residuals:\n",
        "# - bins=30: split the data into 30 equally spaced bars\n",
        "# - edgecolor='k': draw a black border around each bar for visual clarity\n",
        "plt.hist(residuals, bins=30, edgecolor='k')\n",
        "\n",
        "# Draw a vertical dashed line at zero residual to mark where predictions are perfect\n",
        "plt.axvline(0, color='r', linestyle='--')\n",
        "\n",
        "# Label the x-axis to explain what is being plotted\n",
        "plt.xlabel('Residual (Actual − Predicted)')\n",
        "\n",
        "# Label the y-axis to show we’re counting frequencies of residual values\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Add a descriptive title\n",
        "plt.title('Histogram of Residuals')\n",
        "\n",
        "# Automatically adjust subplot parameters so labels/titles fit nicely\n",
        "plt.tight_layout()\n",
        "\n",
        "# Display the histogram\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oE5ETnyfYV4I"
      },
      "source": [
        "# TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwXlSReJYV4I"
      },
      "outputs": [],
      "source": [
        "data_test = pd.read_csv(\"/content/concrete.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "29C4GjamYV4J",
        "outputId": "888fa1df-943b-420c-bb15-954a5573bd3e"
      },
      "outputs": [],
      "source": [
        "data_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "3Lkdm7uh-0px",
        "outputId": "a77890a5-0847-4f4d-e41c-979bf59c02a8"
      },
      "outputs": [],
      "source": [
        "data_test.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "_oPyMvvtYV4J",
        "outputId": "5da2637e-9600-4a1b-8d83-6f47e63fa6f0"
      },
      "outputs": [],
      "source": [
        "# Get the list of all column names (fields) in the DataFrame `data_test`\n",
        "fields = list(data_test.keys())\n",
        "\n",
        "# Initialize empty lists to hold values and scaled values\n",
        "values = []\n",
        "scaled_values = []\n",
        "\n",
        "# Loop through each column (field) in the dataset\n",
        "for field in fields:\n",
        "    # Extract the values of the current field (column)\n",
        "    values = data_test[field]\n",
        "\n",
        "    # Calculate the maximum value in the column\n",
        "    maximum = max(values)\n",
        "\n",
        "    # Calculate the average (mean) value in the column\n",
        "    avg = sum(values) / len(values)\n",
        "\n",
        "    # Loop over each value in the column to compute scaled values\n",
        "    for value in values:\n",
        "        # Scale each value by subtracting the average and dividing by the maximum\n",
        "        scaled_values += [(value - avg) / maximum]\n",
        "\n",
        "    # Convert the scaled_values list into a NumPy array\n",
        "    scaled_values = np.array(scaled_values)\n",
        "\n",
        "    # Add a new column to the DataFrame with the scaled values\n",
        "    data_test[\"Scaled_\" + field] = scaled_values\n",
        "\n",
        "    # Reset scaled_values list for the next field\n",
        "    scaled_values = []\n",
        "\n",
        "# Display the first few rows of the updated DataFrame, including the new scaled columns\n",
        "data_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ec958sdT_eri",
        "outputId": "cfdd91a3-5173-463e-f066-f536c3d95c9c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Select a few example fields (columns) to visualize\n",
        "example_fields = ['cement', 'water']  # adjust as needed\n",
        "\n",
        "# Set up a plot with subplots for each field\n",
        "plt.figure(figsize=(12, 6 * len(example_fields)))\n",
        "\n",
        "for idx, field in enumerate(example_fields):\n",
        "    # Get original and scaled values\n",
        "    original_values = data_test[field].values\n",
        "    scaled_values = data_test['Scaled_' + field].values\n",
        "\n",
        "    # Create a subplot for each field\n",
        "    plt.subplot(len(example_fields), 1, idx + 1)\n",
        "\n",
        "    # Plot original values (blue line)\n",
        "    plt.plot(original_values, label=f'Original {field}', color='blue', marker='o')\n",
        "\n",
        "    # Plot scaled values (orange line)\n",
        "    plt.plot(scaled_values, label=f'Scaled {field}', color='orange', marker='x')\n",
        "\n",
        "    # Add title and legend\n",
        "    plt.title(f'Original vs. Scaled Values for {field}')\n",
        "    plt.xlabel('Sample Index')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "CnAJHygxYV4K",
        "outputId": "3f4a6ec1-6b6e-486d-92f8-7f3bd1cb24b0"
      },
      "outputs": [],
      "source": [
        "# Loop through each field (column name) in the list 'fields'\n",
        "for field in fields:\n",
        "    # Drop (delete) the column from the DataFrame 'data_test'\n",
        "    # axis=1 → means we are dropping a column (not a row)\n",
        "    # inplace=True → apply the change directly to 'data_test' without creating a copy\n",
        "    data_test.drop([field], axis=1, inplace=True)\n",
        "\n",
        "# Display the first few rows of the updated DataFrame (after dropping the original columns)\n",
        "data_test.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4TbiDkFYV4K"
      },
      "outputs": [],
      "source": [
        "Y = data_test[\"Scaled_strength\"]\n",
        "data_test.drop([\"Scaled_strength\"], axis = 1, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "dWiwTdqsYV4L",
        "outputId": "fd9e058a-c3cf-4246-fe2d-0a150c7abcdf"
      },
      "outputs": [],
      "source": [
        "y_predict = model.predict(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zMoiojEAYV4M",
        "outputId": "40fcaa9f-aec6-4417-a1a8-3946a624ae1d"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.scatter(Y, y_predict)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l5Y5I8vYV4M"
      },
      "source": [
        "# Saving model in disk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxjWWNNRYV4N"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = \"Concrete_strength_Lr_Model\"\n",
        "pickle.dump(model, open(filename,\"wb\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
